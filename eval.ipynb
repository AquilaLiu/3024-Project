{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T12:20:16.923457Z",
     "start_time": "2025-11-26T12:20:16.882940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from diffusers import DDPMScheduler, UNet2DModel\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "from torchvision import datasets, transforms\n",
    "CONFIG = {\n",
    "    \"image_size\": 32,\n",
    "    \"batch_size_train\": 32,\n",
    "    \"batch_size_eval\": 32,\n",
    "    \"num_epochs\": 5,\n",
    "    \"lr\": 1e-4,\n",
    "    \"timesteps\": 1000,\n",
    "    \"cfg_scale\": 1,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG[\"image_size\"], CONFIG[\"image_size\"])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]) \n",
    "])\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"batch_size_train\"], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG[\"batch_size_eval\"], shuffle=False)\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=CONFIG[\"timesteps\"],\n",
    "    beta_start=0.0001,\n",
    "    beta_end=0.02,\n",
    "    beta_schedule=\"linear\"\n",
    ")\n",
    "class ClassConditionedUNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, image_size=32):\n",
    "        super().__init__()\n",
    "        self.label_dropout_prob = 0.1\n",
    "        self.null_class_id = num_classes\n",
    "        self.unet = UNet2DModel(\n",
    "            sample_size=image_size,\n",
    "            in_channels=1,\n",
    "            out_channels=1,\n",
    "            layers_per_block=2,\n",
    "            block_out_channels=(128, 256, 256),\n",
    "            down_block_types=(\n",
    "                \"DownBlock2D\", \n",
    "                \"AttnDownBlock2D\",\n",
    "                \"DownBlock2D\"\n",
    "            ),\n",
    "            up_block_types=(\n",
    "                \"UpBlock2D\", \n",
    "                \"AttnUpBlock2D\",\n",
    "                \"UpBlock2D\"\n",
    "            )\n",
    "            ,\n",
    "            class_embed_type=\"timestep\",\n",
    "            num_class_embeds=num_classes + 1,\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t, class_labels=None):\n",
    "        if class_labels is None:\n",
    "            raise ValueError(\"class_labels must be provided.\")\n",
    "        \n",
    "        if self.training:\n",
    "            drop_mask = torch.rand(class_labels.shape[0], device=x.device) < self.label_dropout_prob\n",
    "            class_labels = class_labels.clone()\n",
    "            class_labels[drop_mask] = self.null_class_id\n",
    "        \n",
    "        return self.unet(x, t, class_labels=class_labels).sample\n"
   ],
   "id": "b8ff2c5c0489b28",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate",
   "id": "3109522088efa3c3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-26T12:37:26.174708Z",
     "start_time": "2025-11-26T12:20:16.924957Z"
    }
   },
   "source": [
    "\n",
    "model = ClassConditionedUNet(num_classes=10, image_size=CONFIG[\"image_size\"])\n",
    "model.load_state_dict(torch.load('mnist_diffusion_model.pth'))\n",
    "model=model.to(CONFIG[\"device\"])\n",
    "\n",
    "def to_rgb_grayscale(tensor):\n",
    "    return tensor.repeat(1, 3, 1, 1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_samples(model, noise_scheduler, num_samples=1000, guidance_scale=7.5, \n",
    "                     num_classes=10, image_size=32, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    class_labels = torch.randint(0, num_classes, (num_samples,), device=device)\n",
    "    generator = torch.Generator(device=device).manual_seed(42)\n",
    "    latents = torch.randn(\n",
    "        num_samples, 1, image_size, image_size,\n",
    "        generator=generator, device=device\n",
    "    )\n",
    "    for t in tqdm(noise_scheduler.timesteps, desc=\"Sampling\"):\n",
    "        latent_model_input = torch.cat([latents] * 2)\n",
    "        latent_model_input = noise_scheduler.scale_model_input(latent_model_input, t)\n",
    "        uncond_latents = latent_model_input[:num_samples]\n",
    "        cond_latents = latent_model_input[num_samples:]\n",
    "        null_labels = torch.full_like(class_labels, model.null_class_id)\n",
    "        noise_pred_uncond = model(uncond_latents, t, class_labels=null_labels)\n",
    "        noise_pred_cond = model(cond_latents, t, class_labels=class_labels)\n",
    "        noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_cond - noise_pred_uncond)\n",
    "        latents = noise_scheduler.step(noise_pred, t, latents).prev_sample\n",
    "    samples = (latents.clamp(-1, 1) + 1) / 2\n",
    "    return samples, class_labels\n",
    "\n",
    "def evaluate(model, noise_scheduler, test_loader, device, num_samples=1):\n",
    "    print(\"Starting Evaluation...\")\n",
    "    print(f\"Generating {num_samples} samples with CFG scale = {CONFIG['cfg_scale']}...\")\n",
    "    gen_samples, gen_labels = generate_samples(\n",
    "        model=model,\n",
    "        noise_scheduler=noise_scheduler,\n",
    "        num_samples=num_samples,\n",
    "        guidance_scale=CONFIG[\"cfg_scale\"],\n",
    "        num_classes=10,\n",
    "        image_size=CONFIG[\"image_size\"],\n",
    "        device=device\n",
    "    )\n",
    "    print(\"Loading real test images...\")\n",
    "    real_images = []\n",
    "    for images, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        images = (images + 1) / 2\n",
    "        real_images.append(images)\n",
    "        if len(real_images) * CONFIG[\"batch_size_eval\"] >= num_samples:\n",
    "            break\n",
    "    real_images = torch.cat(real_images, dim=0)[:num_samples]\n",
    "    save_sample_grid(gen_samples[:64], \"generated_samples.png\",nrow=1)\n",
    "    gen_rgb = to_rgb_grayscale(gen_samples)\n",
    "    real_rgb = to_rgb_grayscale(real_images)\n",
    "    gen_rgb = gen_rgb.float()\n",
    "    real_rgb = real_rgb.float()\n",
    "    print(\"Computing Inception Score...\")\n",
    "    is_metric = InceptionScore(normalize=True).to(device)\n",
    "    is_metric.update(gen_rgb)\n",
    "    is_mean, is_std = is_metric.compute()\n",
    "    print(\"Computing FID...\")\n",
    "    fid_metric = FrechetInceptionDistance(feature=2048, normalize=True).to(device)\n",
    "    fid_metric.update(real_rgb, real=True)\n",
    "    fid_metric.update(gen_rgb, real=False)\n",
    "    fid_score = fid_metric.compute()\n",
    "    metrics = {\n",
    "        \"inception_score_mean\": is_mean.item(),\n",
    "        \"inception_score_std\": is_std.item(),\n",
    "        \"fid_score\": fid_score.item()\n",
    "    }\n",
    "    \n",
    "    print(\"Evaluation Results:\")\n",
    "    print(f\"   Inception Score: {is_mean:.4f} ± {is_std:.4f}\")\n",
    "    print(f\"   FID: {fid_score:.4f}\")\n",
    "    save_sample_grid(gen_samples[:64], \"generated_samples.png\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def save_sample_grid(samples, filename, nrow=8):\n",
    "    from torchvision.utils import make_grid\n",
    "    grid = make_grid(samples[:64], nrow=nrow, padding=2, normalize=True, value_range=(0, 1))\n",
    "    grid_img = transforms.ToPILImage()(grid.cpu())\n",
    "    grid_img.save(filename)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Running Final Evaluation\")\n",
    "print(\"=\"*50)\n",
    "model.eval()\n",
    "eval_metrics = evaluate(\n",
    "    model=model,\n",
    "    noise_scheduler=noise_scheduler,\n",
    "    test_loader=test_loader,\n",
    "    device=CONFIG[\"device\"],\n",
    "    num_samples=1000\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Running Final Evaluation\n",
      "==================================================\n",
      "Starting Evaluation...\n",
      "Generating 1000 samples with CFG scale = 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|██████████| 1000/1000 [17:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading real test images...\n",
      "Computing Inception Score...\n",
      "Computing FID...\n",
      "Evaluation Results:\n",
      "   Inception Score: 1.9070 ± 0.0536\n",
      "   FID: 23.3124\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T12:37:26.177491Z",
     "start_time": "2025-11-26T12:37:26.175712Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9c7412b48569e640",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
